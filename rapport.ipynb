{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9-final"
    },
    "colab": {
      "name": "rapport.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DL-ECE/tp-1-deeplearningbasics-DiDiRWINY/blob/master/rapport.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW60WPVoNrmj"
      },
      "source": [
        "# TP-1 DLBasics\n",
        "\n",
        "## Digit classification using the MNIST dataset\n",
        "\n",
        "In this notebook you will train your first neural network. Feel free to look back at the Lecture-1 slides to complete the cells below. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg_zi4KENrmk"
      },
      "source": [
        "#### Install dependencies freeze by poetry \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLKifvaUNrml",
        "outputId": "1b7c1ba7-c3a5-4dd7-d2f9-763623ca389d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#!python3 -m pip install --upgrade pip\n",
        "#!python3 -m pip install matplotlib numpy scikit-learn==0.23.2\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cb/28/91f26bd088ce8e22169032100d4260614fc3da435025ff389ef1d396a433/pip-20.2.4-py2.py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 3.4MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-20.2.4\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Collecting scikit-learn==0.23.2\n",
            "  Downloading scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.2) (0.17.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.2) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.23.2 threadpoolctl-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yganwrZvNrmp"
      },
      "source": [
        "#### Import the different module we will need in this notebook \n",
        "\n",
        "All the dependencies are installed. Below we import them and will be using them in all our notebooks.\n",
        "\n",
        "Please feel free to look arround and look at their API. \n",
        "\n",
        "The student should be limited to these imports to complete this work.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjUsUJ83Nrmq"
      },
      "source": [
        "# We import some python standard librairy utility function \n",
        "# see the [python doc](https://docs.python.org/3.6/library/functools.html?highlight=func#module-functools) for more info \n",
        "from functools import reduce \n",
        "import random \n",
        "\n",
        "# To create some plot and figures: matplolib [matplotlib doc](https://matplotlib.org/)\n",
        "# To do compute on matrix and vectors: [numpy doc](https://numpy.org/)\n",
        "# To do some classical Machine Learning: [sklearn doc](https://scikit-learn.org/stable/index.html)\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8eGrULcNrms"
      },
      "source": [
        "# In order to have some reproducable results and easier debugging \n",
        "# we fix the seed of random.\n",
        "random.seed(1342)\n",
        "np.random.seed(1342)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HRSNoi2Nrmw"
      },
      "source": [
        "## Data preparation (3 pts)\n",
        "\n",
        "As seen in the lecture one of the earlier use case for deep learning was digit recognition. \n",
        "\n",
        "The dataset we will use today is the MNISTdataset http://yann.lecun.com/exdb/mnist/. \n",
        "\n",
        "One image will be represented a vector (a 28x28 image will be represented as vector with 784 entries).\n",
        "\n",
        "Thus, we will end up with a n_examples x 784 matrix to represent the images in the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZBrZ8EqNrmw"
      },
      "source": [
        "mnist_data, mnist_target = fetch_openml('mnist_784', version=1, return_X_y=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTSYQe24Nrmy"
      },
      "source": [
        "# Let's warmup and answer this first question\n",
        "# Replace the None with you answer.\n",
        "\n",
        "# How many image are in this dataset ? \n",
        "def data_length(dataset: np.array, target: np.array):\n",
        "    \"\"\"Function to compute the length of the dataset and the length of the target labels.\"\"\"\n",
        "    dataset_length = np.shape(dataset)[0]\n",
        "    target_length = np.shape(target)[0]\n",
        "    return dataset_length, target_length\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CizX1RbfNrm1",
        "outputId": "e36d4f1a-837d-4db0-e880-8aed68d6be6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "# Let's look at on image from this dataset \n",
        "def plot_one_image(dataset: np.array, target: np.array, image_index: int):\n",
        "    \"\"\"Function to plot the image at the given index.\"\"\"\n",
        "    image = dataset[image_index].reshape(28,28)\n",
        "    target = target[image_index]\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.title(f\"This is a {target}\")\n",
        "\n",
        "\n",
        "plot_one_image(mnist_data, mnist_target ,69999)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARD0lEQVR4nO3df+xV9X3H8edLFIyCClMJVQtaXbVitCtjxmFnpzKmiwiLv5a1rHahc5WgIWm1M5ZNDfXnorF0wUiKUnFm1UmaZtWaUtoms6JWkNJW5ccqgS8aNquuCsJ7f9yD+6Lf8znf7z33F3xej+Sb773nfc85b66+vuece+45H0UEZrb/O6DbDZhZZzjsZplw2M0y4bCbZcJhN8uEw26WCYd9PyBpvqSlifpaSecMcZlnS/pV7easZxzY7QasmqS3+j09BHgX2FU8/2LV/BFx6lDXGRE/Bj4+1PmGStIhwB3ApcBBwAsR8el2rzdHDvs+ICJG7nksaSPwtxHxg37T5nehrVZZROP/w1OA7cAZ3W1n/+Xd+P3HcEkPSHqz2G2ftKcgaaOk84rHkyWtkvRbSX2S7hpoYZLOkfRqv+dfkbS5WP6vJJ1bMt+Fkp4vlv+b1B8iSScDFwGzI+K1iNgVEc82+e+3Cg77/uMi4GHgCGA5cG/J6+4G7o6Iw4CPAY9ULVjSx4GrgT+MiFHAnwEbS17+NvC5oo8LgaskXVzy2snAJuAfJb0uaY2kv6zqx5rjsO8/fhIR34uIXcCDwOklr9sJnCjpyIh4KyL+cxDL3gWMAD4h6aCI2BgRrwz0wohYERFrImJ3RKwGlgF/UrLcY4GJwBvAR2j8QVki6ZRB9GRD5LDvP7b2e/y/wMGSBvpM5gvA7wO/lPSMpL+oWnBEvAxcA8wHtkl6WNJHBnqtpD+S9ENJr0l6A/g74MiSRf+Oxh+fmyNiR0T8CPghMLWqJxs6hz0zEfFSRFwBHA3cCvybpEMHMd9DETEFGA9EMe9AHqJxGHFcRBwO/AugkteuHmhVVb1Ycxz2zEj6a0lHRcRu4H+Kybsr5vm4pD+VNAJ4h8YWuWyeUcD2iHhH0mTgrxKLXgn8F3C9pAMl/THwGeD7Q/gn2SA57PmZBqwtzt3fDVweEb+rmGcE8HXgdRqHC0cD15e89u+Bf5L0JnAjiQ8AI2InMB24gMZx+33A5yLil4P/59hgyTevMMuDt+xmmXDYzTLhsJtlwmE3y0RHL4SR5E8DzdosIgb8XkOtLbukacVFES9Luq7OssysvZo+9SZpGPBr4HzgVeAZ4IqI+EViHm/ZzdqsHVv2ycDLEbE+InbQuOJqeo3lmVkb1Qn7McBv+j1/tZi2F0mzi+unV9VYl5nV1PYP6CJiEY27kXg33qyL6mzZNwPH9Xt+bDHNzHpQnbA/A5wk6XhJw4HLaVzaaGY9qOnd+Ih4T9LVNC5HHAYsjoi1LevMzFqqo1e9+ZjdrP3a8qUaM9t3OOxmmXDYzTLhsJtlwmE3y4TDbpYJD+xoXXPwwQcn63PmzEnWb7vttmR9/fr1pbUbbrghOe+yZcuS9X2Rt+xmmXDYzTLhsJtlwmE3y4TDbpYJh90sEz71ZrWMGjUqWZ85c2Zp7ctf/nJy3lNOOSVZr7pi8/jjjy+tnX/++cl5ferNzPZZDrtZJhx2s0w47GaZcNjNMuGwm2XCYTfLhM+zZ+6II45I1qdPTw/fN2/evGR94sSJQ+5psN55551kfcGCBaW1b3zjG61up+d5y26WCYfdLBMOu1kmHHazTDjsZplw2M0y4bCbZcLn2fcDJ598cmntzDPPTM47d+7cZP30009P1qUBBwx9X51Rgp9++ulk/frrr0/WV6xY0fS690e1wi5pI/AmsAt4LyImtaIpM2u9VmzZPxMRr7dgOWbWRj5mN8tE3bAH8ISkZyXNHugFkmZLWiVpVc11mVkNdXfjp0TEZklHA09K+mVErOz/gohYBCwCkNT8pzVmVkutLXtEbC5+bwMeAya3oikza72mwy7pUEmj9jwGpgIvtqoxM2utOrvxY4HHivOsBwIPRcR/tKSrzFRd83377bcn62eddVZpreq+7t1UdR59xowZyfrWrVtb2c5+r+mwR8R6IP2NCzPrGT71ZpYJh90sEw67WSYcdrNMOOxmmVCdSxCHvDJ/g25Ahx9+eLJ+2mmnNb3sOXPmJOuXXHJJ08uG6ktcf/azn5XWLrroouS8fX19TfWUu4gY8D+Kt+xmmXDYzTLhsJtlwmE3y4TDbpYJh90sEw67WSZ8nn0/MHXq1NLa8uXLk/MOHz681rqrhk0eP358ae21116rtW4bmM+zm2XOYTfLhMNulgmH3SwTDrtZJhx2s0w47GaZ8JDN+4ALL7wwWb/llltKa3XPo69evTpZv+OOO5J1n0vvHd6ym2XCYTfLhMNulgmH3SwTDrtZJhx2s0w47GaZ8Hn2HjB9+vRk/c4770zWTzjhhFa2s5cnn3wyWV+6dGnb1m2tVblll7RY0jZJL/abNkbSk5JeKn6Pbm+bZlbXYHbjvwVM+8C064CnIuIk4KniuZn1sMqwR8RKYPsHJk8HlhSPlwAXt7gvM2uxZo/Zx0bEluLxVmBs2QslzQZmN7keM2uR2h/QRUSkbiQZEYuAReAbTpp1U7On3vokjQMofm9rXUtm1g7Nhn05MKt4PAt4vDXtmFm7VN43XtIy4BzgSKAP+Brw78AjwEeBTcClEfHBD/EGWlaWu/FXXXVVsn7PPfck68OGDWtlO3s58cQTk/UNGzYk650cd8AGp+y+8ZXH7BFxRUnp3FodmVlH+euyZplw2M0y4bCbZcJhN8uEw26WCV/i2gKzZs1K1hcuXNihTj6sqrf169d3qJOhqzrleMghh7Rt3Tt37kzWq4aq7kXesptlwmE3y4TDbpYJh90sEw67WSYcdrNMOOxmmfB59hYYOXJkst7uy0Cff/750trjj/furQaOOuqoZL3q0t/LLrusle3sZd26dcn6eeedl6xv2bIlWe8Gb9nNMuGwm2XCYTfLhMNulgmH3SwTDrtZJhx2s0xU3kq6pSvbh28lPWHChNLaE088kZy36nbNVRYsWJCsp4ZVXrFiRa11jxkzJlkfN25csj5v3rzS2mGHHZacd+bMmcl6Nz344IPJ+uc///lkfffu3a1sZy9lt5L2lt0sEw67WSYcdrNMOOxmmXDYzTLhsJtlwmE3y4TPsxeq7lG+dOnS0lrd66rffvvtZP3ss89O1jdt2lRaGz9+fHLeuXPnJuuTJk1K1idOnJis5zqk86hRo5L1qv/mdTR9nl3SYknbJL3Yb9p8SZsl/bz4uaCVzZpZ6w1mN/5bwLQBpv9zRJxR/HyvtW2ZWatVhj0iVgLbO9CLmbVRnQ/orpa0utjNH132IkmzJa2StKrGusyspmbD/k3gY8AZwBbgzrIXRsSiiJgUEelPesysrZoKe0T0RcSuiNgN3AdMbm1bZtZqTYVdUv/rGmcAL5a91sx6Q+V94yUtA84BjpT0KvA14BxJZwABbAS+2MYeO2LEiBHJ+pQpU9q27ldeeSVZ37BhQ7K+ePHi0tqMGTOa6qlVduzYUVpbvXp1ct6qc/xr165tqieAU089tel5AZYvX56sv/vuu7WW3w6VYY+IKwaYfH8bejGzNvLXZc0y4bCbZcJhN8uEw26WCYfdLBMesnmQDjigfX8XR48u/bYxANOmDXQd0v+bOnVqK9vZS+o21QA33XRTsp469bZmzZrkvJ/61KeS9aphke+9997SWt1TbzfffHOy/t5779Vafjt4y26WCYfdLBMOu1kmHHazTDjsZplw2M0y4bCbZcK3ki5U3fr3jTfe6FAnH7Zt27Zk/eijj27bumfNmpWst/NSzrFjxybrc+bMSdbrDJV96623Jus33nhjsr5z586m112Xh2w2y5zDbpYJh90sEw67WSYcdrNMOOxmmXDYzTLh8+yFquvVr7322tLa7bff3up29hnSgKd039erQzbvy+fRq/g8u1nmHHazTDjsZplw2M0y4bCbZcJhN8uEw26Wicrz7JKOAx4AxtIYonlRRNwtaQzwr8AEGsM2XxoR/12xrN486ToIw4YNK60tXbo0Oe9ll13W6nZ6RjfPs1cNm5y6t/sLL7yQnLeXz6NXqXOe/T1gXkR8AjgT+JKkTwDXAU9FxEnAU8VzM+tRlWGPiC0R8Vzx+E1gHXAMMB1YUrxsCXBxu5o0s/qGdMwuaQLwSeBpYGxE7Bl/ZyuN3Xwz61GDHutN0kjgO8A1EfHb/sdqERFlx+OSZgOz6zZqZvUMassu6SAaQf92RDxaTO6TNK6ojwMGvCtiRCyKiEkRMakVDZtZcyrDrsYm/H5gXUTc1a+0HNhz69FZwOOtb8/MWmUwp96mAD8G1gC7i8lfpXHc/gjwUWATjVNv2yuWtc+eeksZMWJEsn7ssccm61deeWWy/tnPfrbW8uv46U9/mqyvXLmybevu6+tL1hcuXJis9+KwyZ1Qduqt8pg9In4ClJ1MPbdOU2bWOf4GnVkmHHazTDjsZplw2M0y4bCbZcJhN8uEbyVttp/xraTNMuewm2XCYTfLhMNulgmH3SwTDrtZJhx2s0w47GaZcNjNMuGwm2XCYTfLhMNulgmH3SwTDrtZJhx2s0w47GaZcNjNMuGwm2XCYTfLhMNulgmH3SwTDrtZJhx2s0xUhl3ScZJ+KOkXktZKmltMny9ps6SfFz8XtL9dM2tW5SARksYB4yLiOUmjgGeBi4FLgbci4o5Br8yDRJi1XdkgEQcOYsYtwJbi8ZuS1gHHtLY9M2u3IR2zS5oAfBJ4uph0taTVkhZLGl0yz2xJqyStqtWpmdUy6LHeJI0EfgTcEhGPShoLvA4EcBONXf0rK5bh3XizNivbjR9U2CUdBHwX+H5E3DVAfQLw3YiYWLEch92szZoe2FGSgPuBdf2DXnxwt8cM4MW6TZpZ+wzm0/gpwI+BNcDuYvJXgSuAM2jsxm8Evlh8mJdalrfsZm1Waze+VRx2s/bz+OxmmXPYzTLhsJtlwmE3y4TDbpYJh90sEw67WSYcdrNMOOxmmXDYzTLhsJtlwmE3y4TDbpYJh90sE5U3nGyx14FN/Z4fWUzrRb3aW6/2Be6tWa3sbXxZoaPXs39o5dKqiJjUtQYSerW3Xu0L3FuzOtWbd+PNMuGwm2Wi22Ff1OX1p/Rqb73aF7i3ZnWkt64es5tZ53R7y25mHeKwm2WiK2GXNE3SryS9LOm6bvRQRtJGSWuKYai7Oj5dMYbeNkkv9ps2RtKTkl4qfg84xl6XeuuJYbwTw4x39b3r9vDnHT9mlzQM+DVwPvAq8AxwRUT8oqONlJC0EZgUEV3/AoakTwNvAQ/sGVpL0m3A9oj4evGHcnREfKVHepvPEIfxblNvZcOM/w1dfO9aOfx5M7qxZZ8MvBwR6yNiB/AwML0LffS8iFgJbP/A5OnAkuLxEhr/s3RcSW89ISK2RMRzxeM3gT3DjHf1vUv01RHdCPsxwG/6PX+V3hrvPYAnJD0raXa3mxnA2H7DbG0FxnazmQFUDuPdSR8YZrxn3rtmhj+vyx/QfdiUiPgD4M+BLxW7qz0pGsdgvXTu9JvAx2iMAbgFuLObzRTDjH8HuCYiftu/1s33boC+OvK+dSPsm4Hj+j0/tpjWEyJic/F7G/AYjcOOXtK3ZwTd4ve2Lvfzvojoi4hdEbEbuI8uvnfFMOPfAb4dEY8Wk7v+3g3UV6fet26E/RngJEnHSxoOXA4s70IfHyLp0OKDEyQdCkyl94aiXg7MKh7PAh7vYi976ZVhvMuGGafL713Xhz+PiI7/ABfQ+ET+FeAfutFDSV8nAC8UP2u73RuwjMZu3U4an218Afg94CngJeAHwJge6u1BGkN7r6YRrHFd6m0KjV301cDPi58Luv3eJfrqyPvmr8uaZcIf0JllwmE3y4TDbpYJh90sEw67WSYcdrNMOOxmmfg/VfZv6rAuzqoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "py4qQRQsNrm4"
      },
      "source": [
        "\n",
        "# In a similar fashion to classical machine learning, we will create a test split to known if the neural network is learning well.\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(mnist_data, mnist_target, test_size=0.33, random_state=1342)\n",
        "y_train = y_train.astype(int)\n",
        "y_test = y_test.astype(int)\n",
        "# You the 2 function below to check if they are working properly on this divided dataset.\n",
        "\n",
        "X_train_length, y_train_length = data_length(X_train, y_train)\n",
        "X_test_length, y_test_length = data_length(X_test, y_test)\n",
        "\n",
        "assert X_train_length == y_train_length and X_train_length == 46900\n",
        "assert X_test_length == y_test_length and X_test_length == 23100\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFlh7M9QNrm7",
        "outputId": "2d4c8bfe-ad17-4fae-8a99-bf16fb19cfe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "plot_one_image(X_train, y_train , 120)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a23R9XORNrm9",
        "outputId": "80eca237-c942-4a42-ffe2-4f4bc3af6a1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "plot_one_image(X_test, y_test , 250)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe8RTFBjNrm_"
      },
      "source": [
        "# It's important to normalize the data before feeding it into the neural network\n",
        "def normalize_data(dataset: np.array) -> np.array:\n",
        "    normalized_dataset = dataset/255\n",
        "    return normalized_dataset\n",
        "X_train=normalize_data(X_train)\n",
        "X_test=normalize_data(X_test)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6h6rAarjDHa"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Fq54WHBjE92"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0llaMfkENrnC"
      },
      "source": [
        "It's also important to find a good representation of the target.\n",
        "\n",
        "In this notebook it will be one-hot vector. \n",
        "\n",
        "Complete the below function to turn the target vector into a one-hot matrix.\n",
        "\n",
        "For example, a `[0,1,9]` vector will become the following matrix:\n",
        "\n",
        "`[[1,0,0,0,0,0,0,0,0,0],\n",
        "  [0,1,0,0,0,0,0,0,0,0],\n",
        "  [0,0,0,0,0,0,0,0,0,1]]`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55gDobDZNrnD"
      },
      "source": [
        "def target_to_one_hot(target: np.array) -> np.array:\n",
        "    one_hot_matrix = np.zeros((target.shape[0],10))\n",
        "    for i in range(0,target.shape[0]):\n",
        "        label = int(target[i])\n",
        "        one_hot_matrix[i,label] = 1\n",
        "    return one_hot_matrix\n",
        "y_test=target_to_one_hot(y_test)\n",
        "y_train=target_to_one_hot(y_train)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVrcNfCzNrnE"
      },
      "source": [
        "## Useful functions (3 pts)\n",
        "\n",
        "Implement the sigmoid function, its derivative and the softmax function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhFHaWarNrnF"
      },
      "source": [
        "\n",
        "def sigmoid(M: np.array) -> np.array:\n",
        "    \"\"\"Apply a sigmoid to the input array\"\"\"\n",
        "    sig= 1/(1+np.exp(-M))\n",
        "    return sig\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_K9zfBcaNrnJ"
      },
      "source": [
        "def d_sigmoid(M: np.array)-> np.array:\n",
        "     \"\"\"Compute the derivative of the sigmoid\"\"\" \n",
        "     d_sig = sigmoid(M)*(1-sigmoid(M))\n",
        "     return d_sig\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x05kGNvhNrnM"
      },
      "source": [
        "def softmax(X: np.array)-> np.array:\n",
        "    \"\"\"Apply a softmax to the input array\"\"\"\n",
        "    exp = np.exp(X)\n",
        "    som_exp = np.sum(np.exp(X),axis=1).reshape(-1,1)\n",
        "\n",
        "    return exp/som_exp\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8etzu8rNrnP"
      },
      "source": [
        "## Feed forward NN\n",
        "\n",
        "Now that the data is prepared it's time to create a neural network to learn on this dataset.\n",
        "\n",
        "You can look back at the lecture slides and need to replace the None in the below function in order to have the building blocks of this first neural network. \n",
        "\n",
        "To do so we are now going to create the FFNN class. It will take list of integers to represent the network.\n",
        "\n",
        "One element in the list corresponds to the number of neurones in the layer.\n",
        "`config = [784, 3, 4, 10]` will be an acceptable config: \n",
        "- inputs are 1x784 vectors \n",
        "- the model output should be a vector of size 10 to classify between 10 classes.\n",
        "- in the middle the hidden layer are fully customizable\n",
        "\n",
        "You have to do some implementations and replace the None assignment (variable = None). Do not do it for the Layer object.\n",
        "\n",
        "Warning: None return type for some methods are not supposed to be affected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2735PCjNrnP"
      },
      "source": [
        "class Layer:\n",
        "    def __init__(self):\n",
        "        self.Z = None\n",
        "        self.W = None\n",
        "        self.D = None\n",
        "        self.F = None\n",
        "        self.activation = None"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmRPG59sNrnR"
      },
      "source": [
        "class FFNN:\n",
        "    def __init__(self, config, minibatch_size=100, learning_rate=0.1):\n",
        "        self.layers = []\n",
        "        self.nlayers = len(config)\n",
        "        self.minibatch_size = minibatch_size\n",
        "        self.learning_rate = learning_rate\n",
        "        \n",
        "        input_data = Layer()\n",
        "        # TODO: initialize the Z matrix with the a matrix containing only zeros\n",
        "        # its shape should be (minibatch_size, config[0])\n",
        "        input_data.Z = np.zeros((minibatch_size, config[0]))\n",
        "        self.layers.append(input_data)\n",
        "        \n",
        "        for i in range(1, len(config)):\n",
        "            nnodes = config[i]\n",
        "            layer  = Layer()\n",
        "            nlines_prev, ncols_prev = self.layers[i - 1].Z.shape\n",
        "            # TODO: initilize the weight matrix W in the layer with a random normal distribution\n",
        "            # its shape should be (ncols_prev, nnodes)\n",
        "            layer.W = np.random.normal(0,1,(ncols_prev, nnodes))\n",
        "            # TODO: initilize the matrix Z in the layer with a matrix containing only zeros\n",
        "            # its shape should be (nlines_prev, nnodes)\n",
        "            layer.Z = np.zeros((nlines_prev, nnodes))\n",
        "            # TODO: use the sigmoid activation function\n",
        "            layer.activation = sigmoid \n",
        "            self.layers.append(layer) \n",
        "            \n",
        "            \n",
        "        # TODO: Your last layer activation should be a softmax\n",
        "        self.layers[-1].activation = softmax\n",
        "        \n",
        "\n",
        "    def one_step_forward(self, signal: np.array, cur_layer: Layer)-> np.array:\n",
        "        # Compute the F and Z matrix for the current layer and return Z\n",
        "        \n",
        "        # TODO: Compute the dot product betzeen the signal and the current layer W matrix\n",
        "        S = np.dot(signal,cur_layer.W)\n",
        "        # TODO: Compute the F matrix of the current layer\n",
        "        cur_layer.F = np.transpose((d_sigmoid(S)))\n",
        "        # Compute the activation od the current layer\n",
        "        cur_layer.Z = cur_layer.activation(S)\n",
        "        return cur_layer.Z\n",
        "       \n",
        "    def forward_pass(self, input_data: np.array)-> np.array:\n",
        "        # TODO: perform the whole forward pass using the on_step_forward function\n",
        "        self.layers[0].Z = input_data\n",
        "\n",
        "        for i in range(0,self.nlayers-1):\n",
        "            signal = self.layers[i].Z\n",
        "            cur_layer = self.layers[i+1]\n",
        "            self.layers[i+1].Z = self.one_step_forward(signal, cur_layer)\n",
        "         \n",
        "        return self.layers[-1].Z\n",
        "    \n",
        "    def one_step_backward(self, prev_layer: Layer, cur_layer: Layer)-> Layer:\n",
        "        # TODO: Compute the D matrix of the current layer using the previous layer and return the current layer\n",
        "        Di = cur_layer.F* np.dot(prev_layer.W,prev_layer.D)\n",
        "        cur_layer.D = Di\n",
        "        return cur_layer\n",
        "        \n",
        "    def backward_pass(self, D_out: np.array)-> None:\n",
        "        self.layers[-1].D = D_out.T\n",
        "        # TODO: Compute the D matrix for all the layers (excluding the first one which corresponds to the input itself)\n",
        "        # (you should only use self.layers[1:])\n",
        "        \n",
        "        for i in range(1,self.nlayers-1):\n",
        "            prev_layer= self.layers[-i]\n",
        "            cur_layer= self.layers[-(i+1)]\n",
        "            self.layers[-(i+1)] = self.one_step_backward(prev_layer,cur_layer)\n",
        "            \n",
        "        \n",
        "        \n",
        "    \n",
        "    def update_weights(self, cur_layer: Layer, next_layer: Layer)-> Layer:\n",
        "        # TODO: Update the W matrix of the next_layer using the current_layer and the learning rate\n",
        "        # and return the next_layer\n",
        "\n",
        "        next_layer.W += -self.learning_rate*(np.dot(next_layer.D,cur_layer.Z)).T\n",
        "        \n",
        "        return next_layer\n",
        "    \n",
        "    def update_all_weights(self)-> None:\n",
        "        # TODO: Update all W matrix using the update_weights function\n",
        "\n",
        "        for i in range(self.nlayers-1):\n",
        "          cur_layer = self.layers[i]\n",
        "          next_layer = self.layers[i+1]\n",
        "          self.layers[i+1] = self.update_weights(cur_layer,next_layer)\n",
        "        \n",
        "        \n",
        "    def get_error(self, y_pred: np.array, y_batch: np.array)-> float:\n",
        "        # TODO: return the accuracy on the predictions\n",
        "        # the accuracy should be in the [0.0, 1.0] range\n",
        "        predict = np.argmax(y_pred,axis=1)\n",
        "        true = np.argmax(y_batch,axis=1)\n",
        "        match = 0 \n",
        "\n",
        "        for i in range (len(predict)):\n",
        "          if predict[i] == true[i] :\n",
        "            match +=1\n",
        "        return match/len(predict)\n",
        "    \n",
        "    def get_test_error(self, X: np.array, y: np.array)-> float:\n",
        "        # TODO: Compute the accuracy using the get_error function\n",
        "        nbatch = X.shape[0]\n",
        "        error_sum = 0.0\n",
        "        for i in range(0, nbatch):\n",
        "            X_batch = X[i,:,:].reshape(self.minibatch_size, -1)\n",
        "            y_batch = y[i,:,:].reshape(self.minibatch_size, -1)           \n",
        "            # TODO: get y_pred using the forward pass\n",
        "            y_pred = self.forward_pass(X_batch)\n",
        "            error_sum += self.get_error(y_pred,y_batch)\n",
        "        return error_sum / nbatch\n",
        "            \n",
        "        \n",
        "    def train(self, nepoch, X_train, y_train, X_test, y_test)-> float:\n",
        "        X_train = X_train.reshape(-1, self.minibatch_size, 784)\n",
        "        y_train = y_train.reshape(-1, self.minibatch_size, 10)\n",
        "        \n",
        "        X_test = X_test.reshape(-1, self.minibatch_size, 784)\n",
        "        y_test = y_test.reshape(-1, self.minibatch_size, 10)\n",
        "        \n",
        "        # TODO: Get the number of batch based on X_train's shape\n",
        "        nbatch = X_train.shape[0]\n",
        "        error_test = 0.0\n",
        "        for epoch in range(0, nepoch):\n",
        "            error_sum_train = 0.0\n",
        "            for i in range(0, nbatch):\n",
        "                X_batch = X_train[i,:, :]\n",
        "                y_batch = y_train[i,:, :]\n",
        "        \n",
        "                y_pred = self.forward_pass(X_batch)\n",
        "                self.backward_pass(y_pred - y_batch)\n",
        "                self.update_all_weights()\n",
        "                error_sum_train += self.get_error(y_pred, y_batch)\n",
        "            error_test = self.get_test_error(X_test, y_test)\n",
        "            print(f\"Training accuracy: {error_sum_train / nbatch:.3f}, Test accuracy: {error_test:.3f}\")\n",
        "        return error_test"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-80aGNYNrnT"
      },
      "source": [
        "## Training phase (12 pts)\n",
        "\n",
        "Now, it is time to train the model !!\n",
        "\n",
        "You can play with the different parameters (minibatch_size, nepoch, learning_rate and the number of hidden layers)\n",
        "\n",
        "It's on 12 points because there is a lot of functions to fill but also we want the training best training accuracy. \n",
        "\n",
        "To have all the point your neural network needs to have a Test accuracy > 92 % !! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1hd0koFNrnT"
      },
      "source": [
        "minibatch_size = 5 #5\n",
        "nepoch = 10 #10\n",
        "learning_rate = 0.01 #0.01\n",
        "\n",
        "ffnn = FFNN(config=[784, 99, 99, 10], minibatch_size=minibatch_size, learning_rate=learning_rate)\n",
        "#784 110 110 10"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRBlP17WNrnW",
        "outputId": "8d5ea269-fe77-4c6e-bdb3-6fe0b30476e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "assert X_train.shape[0] % minibatch_size == 0\n",
        "assert X_test.shape[0] % minibatch_size == 0\n",
        "\n",
        "err = ffnn.train(nepoch, X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy: 0.800, Test accuracy: 0.819\n",
            "Training accuracy: 0.811, Test accuracy: 0.827\n",
            "Training accuracy: 0.819, Test accuracy: 0.833\n",
            "Training accuracy: 0.825, Test accuracy: 0.838\n",
            "Training accuracy: 0.831, Test accuracy: 0.844\n",
            "Training accuracy: 0.837, Test accuracy: 0.848\n",
            "Training accuracy: 0.841, Test accuracy: 0.850\n",
            "Training accuracy: 0.845, Test accuracy: 0.852\n",
            "Training accuracy: 0.848, Test accuracy: 0.855\n",
            "Training accuracy: 0.852, Test accuracy: 0.857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQIWThrqNrnY"
      },
      "source": [
        "## Error analysis (2 pts)\n",
        "\n",
        "Here we use a subset of the test data to try and find some miss classification.\n",
        "\n",
        "It will help us understand why the neural network failed sometimes to classify images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NKyXZmVNrnY",
        "outputId": "e7443caf-502f-42ce-b7a4-7a47e172ffc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "nsample = 1000\n",
        "X_demo = X_test[:nsample,:]\n",
        "y_demo = ffnn.forward_pass(X_demo)\n",
        "y_true = y_test[:nsample,:]\n",
        "\n",
        "index_to_plot = 50\n",
        "\n",
        "plot_one_image(X_demo, y_true, index_to_plot)\n",
        "\n",
        "# Compare to the prediction \n",
        "prediction = np.argmax(y_demo[index_to_plot,:])\n",
        "true_target = np.argmax(y_true[index_to_plot,:])\n",
        "\n",
        "# is it the same number ?\n",
        "print(prediction) \n",
        "print(true_target)\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcgfCCCgNrnb",
        "outputId": "6a0519bd-f276-4295-e3ee-bedeac011b1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# loop arround the demo test set and try to find a miss prediction\n",
        "for i in range(0, nsample):   \n",
        "    prediction = np.argmax(y_demo[i:]) # Todo\n",
        "    true_target = np.argmax(y_true[i:]) # Todo\n",
        "    if prediction != true_target:\n",
        "      print(prediction)\n",
        "      print(true_target)\n",
        "      pass        # TODO\n",
        "    "
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1410\n",
            "5\n",
            "1400\n",
            "1\n",
            "1390\n",
            "1\n",
            "1380\n",
            "8\n",
            "1370\n",
            "4\n",
            "1360\n",
            "5\n",
            "1350\n",
            "9\n",
            "1340\n",
            "0\n",
            "1330\n",
            "3\n",
            "1320\n",
            "7\n",
            "1310\n",
            "7\n",
            "1300\n",
            "1\n",
            "1290\n",
            "9\n",
            "1280\n",
            "0\n",
            "1270\n",
            "1\n",
            "1260\n",
            "8\n",
            "1250\n",
            "7\n",
            "1240\n",
            "7\n",
            "1230\n",
            "7\n",
            "1220\n",
            "2\n",
            "1210\n",
            "8\n",
            "1200\n",
            "3\n",
            "1190\n",
            "7\n",
            "1180\n",
            "3\n",
            "1170\n",
            "6\n",
            "1160\n",
            "9\n",
            "1150\n",
            "3\n",
            "1140\n",
            "0\n",
            "1130\n",
            "7\n",
            "1120\n",
            "0\n",
            "1110\n",
            "7\n",
            "1100\n",
            "9\n",
            "1090\n",
            "1\n",
            "1080\n",
            "6\n",
            "1070\n",
            "3\n",
            "1060\n",
            "2\n",
            "1050\n",
            "2\n",
            "1040\n",
            "8\n",
            "1030\n",
            "4\n",
            "1020\n",
            "2\n",
            "1010\n",
            "6\n",
            "1000\n",
            "0\n",
            "990\n",
            "6\n",
            "980\n",
            "5\n",
            "970\n",
            "0\n",
            "960\n",
            "4\n",
            "950\n",
            "2\n",
            "940\n",
            "7\n",
            "930\n",
            "1\n",
            "920\n",
            "9\n",
            "910\n",
            "2\n",
            "900\n",
            "3\n",
            "890\n",
            "9\n",
            "880\n",
            "1\n",
            "870\n",
            "4\n",
            "860\n",
            "1\n",
            "850\n",
            "5\n",
            "840\n",
            "4\n",
            "830\n",
            "9\n",
            "820\n",
            "0\n",
            "810\n",
            "4\n",
            "800\n",
            "8\n",
            "790\n",
            "5\n",
            "780\n",
            "5\n",
            "770\n",
            "2\n",
            "760\n",
            "4\n",
            "750\n",
            "7\n",
            "740\n",
            "0\n",
            "730\n",
            "4\n",
            "720\n",
            "0\n",
            "710\n",
            "0\n",
            "700\n",
            "4\n",
            "690\n",
            "7\n",
            "680\n",
            "6\n",
            "670\n",
            "9\n",
            "660\n",
            "8\n",
            "650\n",
            "0\n",
            "640\n",
            "4\n",
            "630\n",
            "9\n",
            "620\n",
            "1\n",
            "610\n",
            "2\n",
            "600\n",
            "9\n",
            "590\n",
            "3\n",
            "580\n",
            "4\n",
            "570\n",
            "8\n",
            "560\n",
            "4\n",
            "550\n",
            "2\n",
            "540\n",
            "1\n",
            "530\n",
            "0\n",
            "520\n",
            "7\n",
            "510\n",
            "8\n",
            "500\n",
            "9\n",
            "490\n",
            "3\n",
            "480\n",
            "5\n",
            "470\n",
            "9\n",
            "460\n",
            "4\n",
            "450\n",
            "1\n",
            "440\n",
            "0\n",
            "430\n",
            "8\n",
            "420\n",
            "4\n",
            "410\n",
            "6\n",
            "400\n",
            "0\n",
            "390\n",
            "2\n",
            "380\n",
            "0\n",
            "370\n",
            "7\n",
            "360\n",
            "8\n",
            "350\n",
            "2\n",
            "340\n",
            "9\n",
            "330\n",
            "3\n",
            "320\n",
            "0\n",
            "310\n",
            "8\n",
            "300\n",
            "1\n",
            "290\n",
            "9\n",
            "280\n",
            "8\n",
            "270\n",
            "9\n",
            "260\n",
            "5\n",
            "250\n",
            "4\n",
            "240\n",
            "4\n",
            "230\n",
            "2\n",
            "220\n",
            "3\n",
            "210\n",
            "0\n",
            "200\n",
            "8\n",
            "190\n",
            "9\n",
            "180\n",
            "3\n",
            "170\n",
            "0\n",
            "160\n",
            "9\n",
            "150\n",
            "6\n",
            "140\n",
            "7\n",
            "130\n",
            "7\n",
            "120\n",
            "3\n",
            "110\n",
            "2\n",
            "100\n",
            "6\n",
            "90\n",
            "4\n",
            "80\n",
            "0\n",
            "70\n",
            "0\n",
            "60\n",
            "5\n",
            "50\n",
            "2\n",
            "40\n",
            "9\n",
            "30\n",
            "3\n",
            "20\n",
            "2\n",
            "10\n",
            "2\n",
            "1627\n",
            "6\n",
            "1617\n",
            "3\n",
            "1607\n",
            "7\n",
            "1597\n",
            "6\n",
            "1587\n",
            "3\n",
            "1577\n",
            "7\n",
            "1567\n",
            "6\n",
            "1557\n",
            "4\n",
            "1547\n",
            "8\n",
            "1537\n",
            "0\n",
            "1527\n",
            "9\n",
            "1517\n",
            "6\n",
            "1507\n",
            "9\n",
            "1497\n",
            "1\n",
            "1487\n",
            "8\n",
            "1477\n",
            "0\n",
            "1467\n",
            "1\n",
            "1457\n",
            "0\n",
            "1447\n",
            "4\n",
            "1437\n",
            "3\n",
            "1427\n",
            "0\n",
            "1417\n",
            "7\n",
            "1407\n",
            "2\n",
            "1397\n",
            "1\n",
            "1387\n",
            "8\n",
            "1377\n",
            "0\n",
            "1367\n",
            "7\n",
            "1357\n",
            "3\n",
            "1347\n",
            "3\n",
            "1337\n",
            "1\n",
            "1327\n",
            "5\n",
            "1317\n",
            "1\n",
            "1307\n",
            "0\n",
            "1297\n",
            "2\n",
            "1287\n",
            "3\n",
            "1277\n",
            "5\n",
            "1267\n",
            "3\n",
            "1257\n",
            "2\n",
            "1247\n",
            "0\n",
            "1237\n",
            "7\n",
            "1227\n",
            "4\n",
            "1217\n",
            "2\n",
            "1207\n",
            "5\n",
            "1197\n",
            "3\n",
            "1187\n",
            "4\n",
            "1177\n",
            "0\n",
            "1167\n",
            "1\n",
            "1157\n",
            "4\n",
            "1147\n",
            "9\n",
            "1137\n",
            "8\n",
            "1127\n",
            "3\n",
            "1117\n",
            "1\n",
            "1107\n",
            "2\n",
            "1097\n",
            "1\n",
            "1087\n",
            "9\n",
            "1077\n",
            "1\n",
            "1067\n",
            "2\n",
            "1057\n",
            "6\n",
            "1047\n",
            "3\n",
            "1037\n",
            "2\n",
            "1027\n",
            "9\n",
            "1017\n",
            "2\n",
            "1007\n",
            "6\n",
            "997\n",
            "4\n",
            "987\n",
            "9\n",
            "977\n",
            "3\n",
            "967\n",
            "1\n",
            "957\n",
            "2\n",
            "947\n",
            "6\n",
            "937\n",
            "1\n",
            "927\n",
            "8\n",
            "917\n",
            "5\n",
            "907\n",
            "9\n",
            "897\n",
            "8\n",
            "887\n",
            "8\n",
            "877\n",
            "4\n",
            "867\n",
            "3\n",
            "857\n",
            "4\n",
            "847\n",
            "2\n",
            "837\n",
            "4\n",
            "827\n",
            "4\n",
            "817\n",
            "5\n",
            "807\n",
            "8\n",
            "797\n",
            "1\n",
            "787\n",
            "4\n",
            "777\n",
            "6\n",
            "767\n",
            "6\n",
            "757\n",
            "3\n",
            "747\n",
            "9\n",
            "737\n",
            "7\n",
            "727\n",
            "9\n",
            "717\n",
            "8\n",
            "707\n",
            "0\n",
            "697\n",
            "4\n",
            "687\n",
            "9\n",
            "677\n",
            "2\n",
            "667\n",
            "5\n",
            "657\n",
            "0\n",
            "647\n",
            "9\n",
            "637\n",
            "3\n",
            "627\n",
            "1\n",
            "617\n",
            "1\n",
            "607\n",
            "4\n",
            "597\n",
            "0\n",
            "587\n",
            "6\n",
            "577\n",
            "3\n",
            "567\n",
            "4\n",
            "557\n",
            "8\n",
            "547\n",
            "6\n",
            "537\n",
            "1\n",
            "527\n",
            "0\n",
            "517\n",
            "1\n",
            "507\n",
            "4\n",
            "497\n",
            "1\n",
            "487\n",
            "1\n",
            "477\n",
            "7\n",
            "467\n",
            "3\n",
            "457\n",
            "9\n",
            "447\n",
            "8\n",
            "437\n",
            "7\n",
            "427\n",
            "5\n",
            "417\n",
            "0\n",
            "407\n",
            "8\n",
            "397\n",
            "7\n",
            "387\n",
            "1\n",
            "377\n",
            "0\n",
            "367\n",
            "9\n",
            "357\n",
            "7\n",
            "347\n",
            "5\n",
            "337\n",
            "8\n",
            "327\n",
            "2\n",
            "317\n",
            "2\n",
            "307\n",
            "8\n",
            "297\n",
            "8\n",
            "287\n",
            "1\n",
            "277\n",
            "7\n",
            "267\n",
            "8\n",
            "257\n",
            "7\n",
            "247\n",
            "9\n",
            "237\n",
            "4\n",
            "227\n",
            "1\n",
            "217\n",
            "5\n",
            "207\n",
            "1\n",
            "197\n",
            "9\n",
            "187\n",
            "2\n",
            "177\n",
            "8\n",
            "167\n",
            "7\n",
            "157\n",
            "4\n",
            "147\n",
            "9\n",
            "137\n",
            "9\n",
            "127\n",
            "2\n",
            "117\n",
            "2\n",
            "107\n",
            "5\n",
            "97\n",
            "1\n",
            "87\n",
            "7\n",
            "77\n",
            "7\n",
            "67\n",
            "6\n",
            "57\n",
            "1\n",
            "47\n",
            "2\n",
            "37\n",
            "4\n",
            "27\n",
            "7\n",
            "17\n",
            "2\n",
            "2397\n",
            "5\n",
            "2387\n",
            "3\n",
            "2377\n",
            "6\n",
            "2367\n",
            "3\n",
            "2357\n",
            "0\n",
            "2347\n",
            "8\n",
            "2337\n",
            "6\n",
            "2327\n",
            "2\n",
            "2317\n",
            "8\n",
            "2307\n",
            "0\n",
            "2297\n",
            "9\n",
            "2287\n",
            "9\n",
            "2277\n",
            "9\n",
            "2267\n",
            "8\n",
            "2257\n",
            "3\n",
            "2247\n",
            "9\n",
            "2237\n",
            "8\n",
            "2227\n",
            "0\n",
            "2217\n",
            "0\n",
            "2207\n",
            "5\n",
            "2197\n",
            "4\n",
            "2187\n",
            "5\n",
            "2177\n",
            "5\n",
            "2167\n",
            "2\n",
            "2157\n",
            "4\n",
            "2147\n",
            "1\n",
            "2137\n",
            "9\n",
            "2127\n",
            "2\n",
            "2117\n",
            "4\n",
            "2107\n",
            "0\n",
            "2097\n",
            "6\n",
            "2087\n",
            "1\n",
            "2077\n",
            "5\n",
            "2067\n",
            "9\n",
            "2057\n",
            "4\n",
            "2047\n",
            "2\n",
            "2037\n",
            "7\n",
            "2027\n",
            "4\n",
            "2017\n",
            "6\n",
            "2007\n",
            "7\n",
            "1997\n",
            "4\n",
            "1987\n",
            "5\n",
            "1977\n",
            "0\n",
            "1967\n",
            "4\n",
            "1957\n",
            "0\n",
            "1947\n",
            "1\n",
            "1937\n",
            "3\n",
            "1927\n",
            "0\n",
            "1917\n",
            "1\n",
            "1907\n",
            "8\n",
            "1897\n",
            "8\n",
            "1887\n",
            "9\n",
            "1877\n",
            "6\n",
            "1867\n",
            "7\n",
            "1857\n",
            "6\n",
            "1847\n",
            "3\n",
            "1837\n",
            "4\n",
            "1827\n",
            "8\n",
            "1817\n",
            "1\n",
            "1807\n",
            "1\n",
            "1797\n",
            "3\n",
            "1787\n",
            "1\n",
            "1777\n",
            "2\n",
            "1767\n",
            "2\n",
            "1757\n",
            "9\n",
            "1747\n",
            "1\n",
            "1737\n",
            "3\n",
            "1727\n",
            "2\n",
            "1717\n",
            "4\n",
            "1707\n",
            "7\n",
            "1697\n",
            "1\n",
            "1687\n",
            "0\n",
            "1677\n",
            "3\n",
            "1667\n",
            "3\n",
            "1657\n",
            "5\n",
            "1647\n",
            "1\n",
            "1637\n",
            "1\n",
            "1627\n",
            "8\n",
            "1617\n",
            "6\n",
            "1607\n",
            "7\n",
            "1597\n",
            "6\n",
            "1587\n",
            "7\n",
            "1577\n",
            "9\n",
            "1567\n",
            "2\n",
            "1557\n",
            "5\n",
            "1547\n",
            "7\n",
            "1537\n",
            "4\n",
            "1527\n",
            "0\n",
            "1517\n",
            "0\n",
            "1507\n",
            "8\n",
            "1497\n",
            "8\n",
            "1487\n",
            "3\n",
            "1477\n",
            "2\n",
            "1467\n",
            "4\n",
            "1457\n",
            "2\n",
            "1447\n",
            "3\n",
            "1437\n",
            "7\n",
            "1427\n",
            "7\n",
            "1417\n",
            "2\n",
            "1407\n",
            "6\n",
            "1397\n",
            "0\n",
            "1387\n",
            "9\n",
            "1377\n",
            "9\n",
            "1367\n",
            "1\n",
            "1357\n",
            "4\n",
            "1347\n",
            "1\n",
            "1337\n",
            "7\n",
            "1327\n",
            "2\n",
            "1317\n",
            "9\n",
            "1307\n",
            "7\n",
            "1297\n",
            "2\n",
            "1287\n",
            "9\n",
            "1277\n",
            "9\n",
            "1267\n",
            "1\n",
            "1257\n",
            "5\n",
            "1247\n",
            "7\n",
            "1237\n",
            "2\n",
            "1227\n",
            "3\n",
            "1217\n",
            "4\n",
            "1207\n",
            "2\n",
            "1197\n",
            "1\n",
            "1187\n",
            "6\n",
            "1177\n",
            "6\n",
            "1167\n",
            "0\n",
            "1157\n",
            "8\n",
            "1147\n",
            "1\n",
            "1137\n",
            "1\n",
            "1127\n",
            "7\n",
            "1117\n",
            "1\n",
            "1107\n",
            "7\n",
            "1097\n",
            "1\n",
            "1087\n",
            "8\n",
            "1077\n",
            "5\n",
            "1067\n",
            "3\n",
            "1057\n",
            "5\n",
            "1047\n",
            "0\n",
            "1037\n",
            "8\n",
            "1027\n",
            "9\n",
            "1017\n",
            "6\n",
            "1007\n",
            "0\n",
            "997\n",
            "2\n",
            "987\n",
            "6\n",
            "977\n",
            "2\n",
            "967\n",
            "0\n",
            "957\n",
            "9\n",
            "947\n",
            "0\n",
            "937\n",
            "2\n",
            "927\n",
            "1\n",
            "917\n",
            "2\n",
            "907\n",
            "9\n",
            "897\n",
            "3\n",
            "887\n",
            "1\n",
            "877\n",
            "4\n",
            "867\n",
            "5\n",
            "857\n",
            "2\n",
            "847\n",
            "3\n",
            "837\n",
            "2\n",
            "827\n",
            "4\n",
            "817\n",
            "7\n",
            "807\n",
            "1\n",
            "797\n",
            "0\n",
            "787\n",
            "9\n",
            "777\n",
            "0\n",
            "767\n",
            "1\n",
            "757\n",
            "5\n",
            "747\n",
            "3\n",
            "737\n",
            "0\n",
            "727\n",
            "2\n",
            "717\n",
            "4\n",
            "707\n",
            "9\n",
            "697\n",
            "0\n",
            "687\n",
            "4\n",
            "677\n",
            "8\n",
            "667\n",
            "8\n",
            "657\n",
            "9\n",
            "647\n",
            "3\n",
            "637\n",
            "3\n",
            "627\n",
            "0\n",
            "617\n",
            "9\n",
            "607\n",
            "1\n",
            "597\n",
            "2\n",
            "587\n",
            "6\n",
            "577\n",
            "5\n",
            "567\n",
            "2\n",
            "557\n",
            "1\n",
            "547\n",
            "3\n",
            "537\n",
            "9\n",
            "527\n",
            "4\n",
            "517\n",
            "0\n",
            "507\n",
            "2\n",
            "497\n",
            "7\n",
            "487\n",
            "2\n",
            "477\n",
            "8\n",
            "467\n",
            "0\n",
            "457\n",
            "5\n",
            "447\n",
            "9\n",
            "437\n",
            "2\n",
            "427\n",
            "4\n",
            "417\n",
            "8\n",
            "407\n",
            "1\n",
            "397\n",
            "5\n",
            "387\n",
            "9\n",
            "377\n",
            "2\n",
            "367\n",
            "1\n",
            "357\n",
            "2\n",
            "347\n",
            "5\n",
            "337\n",
            "9\n",
            "327\n",
            "5\n",
            "317\n",
            "8\n",
            "307\n",
            "0\n",
            "297\n",
            "6\n",
            "287\n",
            "8\n",
            "277\n",
            "1\n",
            "267\n",
            "3\n",
            "257\n",
            "1\n",
            "247\n",
            "6\n",
            "237\n",
            "2\n",
            "227\n",
            "6\n",
            "217\n",
            "1\n",
            "207\n",
            "8\n",
            "197\n",
            "2\n",
            "187\n",
            "1\n",
            "177\n",
            "5\n",
            "167\n",
            "6\n",
            "157\n",
            "3\n",
            "147\n",
            "5\n",
            "137\n",
            "1\n",
            "127\n",
            "4\n",
            "117\n",
            "1\n",
            "107\n",
            "9\n",
            "97\n",
            "7\n",
            "87\n",
            "1\n",
            "77\n",
            "7\n",
            "67\n",
            "8\n",
            "57\n",
            "5\n",
            "47\n",
            "5\n",
            "37\n",
            "2\n",
            "27\n",
            "7\n",
            "17\n",
            "7\n",
            "2042\n",
            "5\n",
            "2032\n",
            "2\n",
            "2022\n",
            "0\n",
            "2012\n",
            "7\n",
            "2002\n",
            "9\n",
            "1992\n",
            "3\n",
            "1982\n",
            "2\n",
            "1972\n",
            "2\n",
            "1962\n",
            "5\n",
            "1952\n",
            "7\n",
            "1942\n",
            "7\n",
            "1932\n",
            "6\n",
            "1922\n",
            "5\n",
            "1912\n",
            "4\n",
            "1902\n",
            "5\n",
            "1892\n",
            "8\n",
            "1882\n",
            "8\n",
            "1872\n",
            "4\n",
            "1862\n",
            "3\n",
            "1852\n",
            "9\n",
            "1842\n",
            "6\n",
            "1832\n",
            "9\n",
            "1822\n",
            "8\n",
            "1812\n",
            "0\n",
            "1802\n",
            "6\n",
            "1792\n",
            "4\n",
            "1782\n",
            "6\n",
            "1772\n",
            "3\n",
            "1762\n",
            "8\n",
            "1752\n",
            "8\n",
            "1742\n",
            "7\n",
            "1732\n",
            "2\n",
            "1722\n",
            "1\n",
            "1712\n",
            "0\n",
            "1702\n",
            "3\n",
            "1692\n",
            "7\n",
            "1682\n",
            "9\n",
            "1672\n",
            "3\n",
            "1662\n",
            "4\n",
            "1652\n",
            "8\n",
            "1642\n",
            "0\n",
            "1632\n",
            "5\n",
            "1622\n",
            "4\n",
            "1612\n",
            "6\n",
            "1602\n",
            "0\n",
            "1592\n",
            "6\n",
            "1582\n",
            "0\n",
            "1572\n",
            "7\n",
            "1562\n",
            "9\n",
            "1552\n",
            "1\n",
            "1542\n",
            "9\n",
            "1532\n",
            "5\n",
            "1522\n",
            "4\n",
            "1512\n",
            "4\n",
            "1502\n",
            "5\n",
            "1492\n",
            "9\n",
            "1482\n",
            "4\n",
            "1472\n",
            "2\n",
            "1462\n",
            "1\n",
            "1452\n",
            "4\n",
            "1442\n",
            "4\n",
            "1432\n",
            "6\n",
            "1422\n",
            "8\n",
            "1412\n",
            "3\n",
            "1402\n",
            "5\n",
            "1392\n",
            "8\n",
            "1382\n",
            "4\n",
            "1372\n",
            "9\n",
            "1362\n",
            "0\n",
            "1352\n",
            "8\n",
            "1342\n",
            "9\n",
            "1332\n",
            "6\n",
            "1322\n",
            "1\n",
            "1312\n",
            "5\n",
            "1302\n",
            "8\n",
            "1292\n",
            "0\n",
            "1282\n",
            "7\n",
            "1272\n",
            "6\n",
            "1262\n",
            "6\n",
            "1252\n",
            "4\n",
            "1242\n",
            "7\n",
            "1232\n",
            "9\n",
            "1222\n",
            "4\n",
            "1212\n",
            "0\n",
            "1202\n",
            "0\n",
            "1192\n",
            "0\n",
            "1182\n",
            "9\n",
            "1172\n",
            "3\n",
            "1162\n",
            "9\n",
            "1152\n",
            "6\n",
            "1142\n",
            "6\n",
            "1132\n",
            "3\n",
            "1122\n",
            "1\n",
            "1112\n",
            "7\n",
            "1102\n",
            "9\n",
            "1092\n",
            "4\n",
            "1082\n",
            "9\n",
            "1072\n",
            "3\n",
            "1062\n",
            "8\n",
            "1052\n",
            "0\n",
            "1042\n",
            "4\n",
            "1032\n",
            "6\n",
            "1022\n",
            "6\n",
            "1012\n",
            "4\n",
            "1002\n",
            "2\n",
            "992\n",
            "8\n",
            "982\n",
            "3\n",
            "972\n",
            "2\n",
            "962\n",
            "1\n",
            "952\n",
            "4\n",
            "942\n",
            "9\n",
            "932\n",
            "2\n",
            "922\n",
            "4\n",
            "912\n",
            "2\n",
            "902\n",
            "4\n",
            "892\n",
            "0\n",
            "882\n",
            "3\n",
            "872\n",
            "3\n",
            "862\n",
            "2\n",
            "852\n",
            "0\n",
            "842\n",
            "5\n",
            "832\n",
            "4\n",
            "822\n",
            "8\n",
            "812\n",
            "9\n",
            "802\n",
            "8\n",
            "792\n",
            "2\n",
            "782\n",
            "4\n",
            "772\n",
            "0\n",
            "762\n",
            "2\n",
            "752\n",
            "5\n",
            "742\n",
            "7\n",
            "732\n",
            "0\n",
            "722\n",
            "0\n",
            "712\n",
            "6\n",
            "702\n",
            "2\n",
            "692\n",
            "6\n",
            "682\n",
            "1\n",
            "672\n",
            "9\n",
            "662\n",
            "5\n",
            "652\n",
            "0\n",
            "642\n",
            "9\n",
            "632\n",
            "8\n",
            "622\n",
            "9\n",
            "612\n",
            "5\n",
            "602\n",
            "9\n",
            "592\n",
            "7\n",
            "582\n",
            "4\n",
            "572\n",
            "7\n",
            "562\n",
            "3\n",
            "552\n",
            "6\n",
            "542\n",
            "0\n",
            "532\n",
            "9\n",
            "522\n",
            "2\n",
            "512\n",
            "1\n",
            "502\n",
            "8\n",
            "492\n",
            "6\n",
            "482\n",
            "1\n",
            "472\n",
            "3\n",
            "462\n",
            "3\n",
            "452\n",
            "2\n",
            "442\n",
            "0\n",
            "432\n",
            "2\n",
            "422\n",
            "9\n",
            "412\n",
            "1\n",
            "402\n",
            "6\n",
            "392\n",
            "8\n",
            "382\n",
            "5\n",
            "372\n",
            "6\n",
            "362\n",
            "6\n",
            "352\n",
            "0\n",
            "342\n",
            "2\n",
            "332\n",
            "3\n",
            "322\n",
            "4\n",
            "312\n",
            "4\n",
            "302\n",
            "6\n",
            "292\n",
            "6\n",
            "282\n",
            "1\n",
            "272\n",
            "7\n",
            "262\n",
            "1\n",
            "252\n",
            "1\n",
            "242\n",
            "3\n",
            "232\n",
            "3\n",
            "222\n",
            "4\n",
            "212\n",
            "9\n",
            "202\n",
            "2\n",
            "192\n",
            "0\n",
            "182\n",
            "8\n",
            "172\n",
            "8\n",
            "162\n",
            "1\n",
            "152\n",
            "0\n",
            "142\n",
            "6\n",
            "132\n",
            "6\n",
            "122\n",
            "1\n",
            "112\n",
            "1\n",
            "102\n",
            "3\n",
            "92\n",
            "8\n",
            "82\n",
            "9\n",
            "72\n",
            "4\n",
            "62\n",
            "2\n",
            "52\n",
            "3\n",
            "42\n",
            "5\n",
            "32\n",
            "4\n",
            "22\n",
            "6\n",
            "12\n",
            "0\n",
            "420\n",
            "5\n",
            "410\n",
            "7\n",
            "400\n",
            "7\n",
            "390\n",
            "3\n",
            "380\n",
            "4\n",
            "370\n",
            "0\n",
            "360\n",
            "0\n",
            "350\n",
            "2\n",
            "340\n",
            "4\n",
            "330\n",
            "8\n",
            "320\n",
            "7\n",
            "310\n",
            "6\n",
            "300\n",
            "3\n",
            "290\n",
            "9\n",
            "280\n",
            "3\n",
            "270\n",
            "4\n",
            "260\n",
            "4\n",
            "250\n",
            "0\n",
            "240\n",
            "3\n",
            "230\n",
            "5\n",
            "220\n",
            "4\n",
            "210\n",
            "6\n",
            "200\n",
            "5\n",
            "190\n",
            "8\n",
            "180\n",
            "6\n",
            "170\n",
            "5\n",
            "160\n",
            "5\n",
            "150\n",
            "0\n",
            "140\n",
            "1\n",
            "130\n",
            "6\n",
            "120\n",
            "0\n",
            "110\n",
            "7\n",
            "100\n",
            "5\n",
            "90\n",
            "4\n",
            "80\n",
            "0\n",
            "70\n",
            "8\n",
            "60\n",
            "4\n",
            "50\n",
            "8\n",
            "40\n",
            "2\n",
            "30\n",
            "7\n",
            "20\n",
            "9\n",
            "10\n",
            "3\n",
            "1037\n",
            "5\n",
            "1027\n",
            "2\n",
            "1017\n",
            "4\n",
            "1007\n",
            "5\n",
            "997\n",
            "8\n",
            "987\n",
            "4\n",
            "977\n",
            "8\n",
            "967\n",
            "9\n",
            "957\n",
            "1\n",
            "947\n",
            "1\n",
            "937\n",
            "9\n",
            "927\n",
            "1\n",
            "917\n",
            "2\n",
            "907\n",
            "4\n",
            "897\n",
            "9\n",
            "887\n",
            "3\n",
            "877\n",
            "5\n",
            "867\n",
            "9\n",
            "857\n",
            "3\n",
            "847\n",
            "4\n",
            "837\n",
            "1\n",
            "827\n",
            "6\n",
            "817\n",
            "7\n",
            "807\n",
            "7\n",
            "797\n",
            "7\n",
            "787\n",
            "6\n",
            "777\n",
            "1\n",
            "767\n",
            "1\n",
            "757\n",
            "5\n",
            "747\n",
            "4\n",
            "737\n",
            "3\n",
            "727\n",
            "8\n",
            "717\n",
            "4\n",
            "707\n",
            "6\n",
            "697\n",
            "3\n",
            "687\n",
            "1\n",
            "677\n",
            "2\n",
            "667\n",
            "2\n",
            "657\n",
            "4\n",
            "647\n",
            "0\n",
            "637\n",
            "1\n",
            "627\n",
            "8\n",
            "617\n",
            "3\n",
            "607\n",
            "0\n",
            "597\n",
            "3\n",
            "587\n",
            "5\n",
            "577\n",
            "9\n",
            "567\n",
            "9\n",
            "557\n",
            "5\n",
            "547\n",
            "0\n",
            "537\n",
            "7\n",
            "527\n",
            "4\n",
            "517\n",
            "4\n",
            "507\n",
            "9\n",
            "497\n",
            "2\n",
            "487\n",
            "0\n",
            "477\n",
            "8\n",
            "467\n",
            "1\n",
            "457\n",
            "6\n",
            "447\n",
            "3\n",
            "437\n",
            "7\n",
            "427\n",
            "8\n",
            "417\n",
            "5\n",
            "407\n",
            "0\n",
            "397\n",
            "2\n",
            "387\n",
            "5\n",
            "377\n",
            "0\n",
            "367\n",
            "4\n",
            "357\n",
            "0\n",
            "347\n",
            "8\n",
            "337\n",
            "1\n",
            "327\n",
            "4\n",
            "317\n",
            "1\n",
            "307\n",
            "7\n",
            "297\n",
            "0\n",
            "287\n",
            "9\n",
            "277\n",
            "8\n",
            "267\n",
            "7\n",
            "257\n",
            "5\n",
            "247\n",
            "4\n",
            "237\n",
            "8\n",
            "227\n",
            "9\n",
            "217\n",
            "3\n",
            "207\n",
            "5\n",
            "197\n",
            "8\n",
            "187\n",
            "8\n",
            "177\n",
            "5\n",
            "167\n",
            "7\n",
            "157\n",
            "1\n",
            "147\n",
            "9\n",
            "137\n",
            "4\n",
            "127\n",
            "6\n",
            "117\n",
            "9\n",
            "107\n",
            "1\n",
            "97\n",
            "1\n",
            "87\n",
            "1\n",
            "77\n",
            "6\n",
            "67\n",
            "2\n",
            "57\n",
            "9\n",
            "47\n",
            "5\n",
            "37\n",
            "9\n",
            "27\n",
            "0\n",
            "17\n",
            "2\n",
            "902\n",
            "7\n",
            "892\n",
            "5\n",
            "882\n",
            "2\n",
            "872\n",
            "5\n",
            "862\n",
            "9\n",
            "852\n",
            "1\n",
            "842\n",
            "3\n",
            "832\n",
            "1\n",
            "822\n",
            "2\n",
            "812\n",
            "4\n",
            "802\n",
            "6\n",
            "792\n",
            "4\n",
            "782\n",
            "6\n",
            "772\n",
            "4\n",
            "762\n",
            "4\n",
            "752\n",
            "0\n",
            "742\n",
            "2\n",
            "732\n",
            "2\n",
            "722\n",
            "2\n",
            "712\n",
            "4\n",
            "702\n",
            "1\n",
            "692\n",
            "8\n",
            "682\n",
            "1\n",
            "672\n",
            "9\n",
            "662\n",
            "3\n",
            "652\n",
            "3\n",
            "642\n",
            "7\n",
            "632\n",
            "0\n",
            "622\n",
            "1\n",
            "612\n",
            "4\n",
            "602\n",
            "4\n",
            "592\n",
            "1\n",
            "582\n",
            "0\n",
            "572\n",
            "9\n",
            "562\n",
            "8\n",
            "552\n",
            "2\n",
            "542\n",
            "6\n",
            "532\n",
            "8\n",
            "522\n",
            "3\n",
            "512\n",
            "4\n",
            "502\n",
            "2\n",
            "492\n",
            "7\n",
            "482\n",
            "1\n",
            "472\n",
            "3\n",
            "462\n",
            "1\n",
            "452\n",
            "1\n",
            "442\n",
            "0\n",
            "432\n",
            "4\n",
            "422\n",
            "0\n",
            "412\n",
            "3\n",
            "402\n",
            "4\n",
            "392\n",
            "3\n",
            "382\n",
            "7\n",
            "372\n",
            "1\n",
            "362\n",
            "9\n",
            "352\n",
            "0\n",
            "342\n",
            "6\n",
            "332\n",
            "3\n",
            "322\n",
            "6\n",
            "312\n",
            "9\n",
            "302\n",
            "6\n",
            "292\n",
            "9\n",
            "282\n",
            "9\n",
            "272\n",
            "2\n",
            "262\n",
            "0\n",
            "252\n",
            "7\n",
            "242\n",
            "3\n",
            "232\n",
            "7\n",
            "222\n",
            "9\n",
            "212\n",
            "9\n",
            "202\n",
            "6\n",
            "192\n",
            "9\n",
            "182\n",
            "9\n",
            "172\n",
            "9\n",
            "162\n",
            "6\n",
            "152\n",
            "6\n",
            "142\n",
            "0\n",
            "132\n",
            "6\n",
            "122\n",
            "4\n",
            "112\n",
            "2\n",
            "102\n",
            "2\n",
            "92\n",
            "1\n",
            "82\n",
            "5\n",
            "72\n",
            "0\n",
            "62\n",
            "4\n",
            "52\n",
            "0\n",
            "42\n",
            "1\n",
            "32\n",
            "2\n",
            "22\n",
            "6\n",
            "12\n",
            "3\n",
            "117\n",
            "9\n",
            "107\n",
            "7\n",
            "97\n",
            "6\n",
            "87\n",
            "4\n",
            "77\n",
            "8\n",
            "67\n",
            "9\n",
            "57\n",
            "9\n",
            "47\n",
            "3\n",
            "37\n",
            "2\n",
            "27\n",
            "9\n",
            "17\n",
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnKrVu9ZNrnd"
      },
      "source": [
        "## Open analysis\n",
        "\n",
        "in the cell below please explain you choice for all the parameters of your configuration: \n",
        "\n",
        "- minibatch_size\n",
        "- nepoch\n",
        "- config\n",
        "- learning_rate\n",
        "\n",
        "Also explain how the neural network behave when changing them ? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2wDqs-aNrne"
      },
      "source": [
        "## Open analysis answer\n",
        "\n",
        "TODO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtqhY47XNrne"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}